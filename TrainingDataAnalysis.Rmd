---
title: "TrainingDataAnalysis"
author: "Ben Weinstein"
date: "January 2, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = F,message = F)
```

```{r}
library(dplyr)
library(ggplot2)
```

```{r}
d<-read.csv("TrainingData/TrainingData.csv",header=F)
d$V2<-as.character(d$V2)
```

# Number of classes
```{r}
length(unique(d$V2))
```

# How many images of each class

```{r}
sort(table(d$V2))
```

#replace slashes and numbers, incase of special character

```{r}
d[d$V2=="/","V2"]<-"Forward_slash"
d[d$V2=="0","V2"]<-"Zero"
d[d$V2=="1","V2"]<-"One"
d[d$V2=="2","V2"]<-"Two"
d[d$V2=="3","V2"]<-"Three"
d[d$V2=="4","V2"]<-"Four"
d[d$V2=="5","V2"]<-"Five"
d[d$V2=="6","V2"]<-"Six"
d[d$V2=="7","V2"]<-"Seven"
d[d$V2=="8","V2"]<-"Eight"
d[d$V2=="9","V2"]<-"Nine"
```

```{r}
classes<-as.character(sort(unique(d$V2)))
write.table(classes,"cloudML/dict.txt",sep="\n",quote=F,row.names = F)
cat(paste(classes, collapse = "\n"), file = "cloudML/dict2.txt") 
```

We are looking for about 200 images per class.

# Split into 80 20 data for each class.
```{r}
#add an identifier
d$ID=1:nrow(d)
a<-d %>% group_by(V2) %>% sample_frac(0.8)
test_data<-d[!d$ID %in% a$ID,c("V1","V2")]
train_data<-d[d$ID %in% a$ID,c("V1","V2")]

write.table(test_data,"cloudML/testing_data.csv",row.names=F,col.names = F,sep=",",quote=F)
write.table(train_data,"cloudML/training_data.csv",col.names=F,row.names=F,sep=",",quote=F)
```